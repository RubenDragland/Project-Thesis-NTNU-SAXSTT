
\chapter{Calculations}

\section{Computing Gradients of Alternative Functional}\label{sec:calc_alt_functional} %Functional is function of functions

% Validation even though not validated.
The first utilisation of automatic differentition was to test the validity of obtained symbolic gradient expressions of the alternative functional EXPSIN, proposed in Section \ref{sec:modelling_scattering}.
The validation of the alternative functional was conducted in stages with increasing complexity.
It was important to be able to contrast errors in the implementation from false gradient expressions.
% Firstly, the gradient of a simple integer scattering model was calculated. The cost function of this model, with its gradient, is listed in Table \ref{tab:integer_model} in Appendix \ref{app:appendixA}.

% Is it actually fitting to keep this in a table? Or would equations suffice? Or necessary at all, or a part of the results?
% Possibly move to appendix.

The test of the parameters $A$ and $B$ from \eqref{eq:exp_sin_squared} was conducted by comparing the symbolic gradient expressions with the automatically calculated gradients for random values.
Since the orientations $\theta_{op}$ and $\varphi_{op}$ were not included in the test, the parameters could be validated by drawing random values for $A$, $B$,
and projection data $I_{n}$.
For each of the projections, the cost function was evaluated, the backpropagation of the gradient was performed, and the result was compared to the evaluation of the symbolically derived gradient expressions.
This procedure was identical to the initial testing of AD described in Section \ref{sec:proof_of_concept_AD}.

Finally, the gradients with respect to the orientation parameters were tested.
For this test, the lab orientation was initially set to $\left( \alpha = 0, \beta = 0 \right)$, and the position coordinate was mostly kept at $\phi = 0$ to simplify the validation.
Since the behaviour of parameter $A$ and $B$ was known, debugging of the final implementation was easier. %? 
In addition, the final parts of the symbolic gradient expression were derived by hand.
%The derivation is listed in Appendix \ref{app:appendixA}.


% Derivation of expressions here or in appendix? Also, orientation symbolic expressions wrong, but unsure if I have done a mistake or if there was a mistake in things derived earlier. 


\section{Reconstruction of Simulated Data}\label{sec:pp_nanostructures_reconstruction}

% RSD: The size was set to ... because.... Each voxel is identical, so the params are the same for each voxel. Nope, not here but in data sets. 
% Experimented a bit with starting conditions. 

The reconstruction script was run for the data sets described in Section \ref{sec:reconstruction_data_sets_periodic_parallel_uniaxial_nanostructures} and \ref{sec:aligned_parallel_nanostructures_in_air}
using both symbolically and automatically calculated gradients.
The same initial conditions were applied to all runs.
$a0$ was initially $10^{-4}$, and the default orientation was set to $\left( \theta = \frac{\pi}{4}, \varphi = \frac{\pi}{4} \right)$.
All anisotropic parameters were set to a be positive, since meridional scattering was expected.

For a given data set size, deeper data analysis was conducted.
Firstly, the respective gradients from the first iteration of optimising the isotropic coefficient $a0$ were compared.
Here, the relative deviation of the automatically calculated gradients from the symbolic gradients was calculated.
Additionally, the location of the largest deviation was determined.

Nevertheless, the accuracy of the reconstructions was measured by analysing converged reconstructions.
This was done by plotting the distribution of reconstructed parameters in the case of automatically and symbolically calculated gradients.
The respective distributions were curve-fitted to Lorentzian distributions, whence the expectation value and the standard deviation of the functions were determined.
The reconstructions had initial orientation close to the true values, so that the algorithms would be able to find the global minimum.

This testing procedure was, however, not useful when all reconstruction algorithms were to be compared.
Hence, the performance of the algorithms was compared qualitatively by studying the resulting 3D reconstructions of the Phantom data set.
These models visualised the degree of anisotropy as well as the orientation of the nanostructures.
Additionally, the centremost 2D slice, with $z = 17$, of each optimisation parameter was extracted from each of the 3D reconstructions, and compared to the true values.

\section{Reconstruction of Carbon Knot}


The main focus in the comparison of the reconstruction algorithms was to assess the performance of the algorithms on the experimental data set.
Each of the implemented algorithms were run on the carbon knot data set using a total of 100 iterations each.
% The procedure mentioned in Section \ref{sec:pp_nanostructures_reconstruction} for the Phantom data set was also applied using the carbon knot projection data.
\noindent
With the exception that coefficients $a2$ and $a6$ were negative, due to anticipated equatorial scattering, the initial conditions were identical to what was used for the Phantom data set.
The resulting 3D reconstructions were compared to one another along different projections, as well as the 2D slices of the optimisation parameters.
Moreover, whether the algorithms managed to perform an orientation mapping in occurdance with the expected orientation of the fibers was assessed.
As a final note, the computational performance of the algorithms, as well as the convergence curves, were compared.